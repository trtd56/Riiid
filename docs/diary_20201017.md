# 20201017
## 概要
- データが更新された
  - lectureが更新されただけっぽいのでとりあえず気にしなくてよい？
- 評価を同時にできるとよさそう？(DATA_SPLIT_COL)うまく使う？
## 学習


### XGBoost

|Fold|precision|recall|accuracy|f1_score|log_loss|roc_auc|
| -- | -- | -- | -- | -- | -- | -- |
|0|0.7422416469692721|0.88321514763281|0.7175163362322527|0.8066151840937353|0.5499874804139089|0.7435684315684316|
|1|0.7439370978623141|0.8803922181955759|0.7188753945749291|0.8064330617075924|0.547818710223756|0.7477652347652347|
|2|0.7425813173983454|0.8797690509194533|0.7170932516612323|0.8053748112566597|0.5496236857469464|0.7451588411588411|
|3|0.742134576603296|0.8773773683546358|0.7174746841915572|0.8041090203902083|0.5498774404666615|0.7483646353646354|
|4|0.7397382298891014|0.8810910733603585|0.7158452891598647|0.8042509469343742|0.5525104522053328|0.7436993006993007|

#### Submit
- [Fold-0](https://www.kaggle.com/takamichitoda/riiid-xgboost-infer?scriptVersionId=44877927): 0.709
- [CV](https://www.kaggle.com/takamichitoda/riiid-xgboost-infer?scriptVersionId=44878035):

## XGBoostのパラメータ

- BOOSTER_TYPE = {'GBTREE' | 'DART'},
  - デフォルト値は gbtree
  - ブースターの種類
  - booster: "gbtree", "dart"
  - dartはDropoutの考え方を入れたやつ
  - 基本gbtreeで良さそう
- NUM_PARALLEL_TREE = int64_value,
  - デフォルト値は 1
  - 各イテレーションで構築される並列ツリーの数。
  - RandomForestの学習で使うから無視して良さそう
- DART_NORMALIZE_TYPE = {'TREE' | 'FOREST'},
  - DART ブースターの正規化アルゴリズムのタイプ
  - デフォルト値は tree
  - dartを使わない場合は無視して良さそう
- TREE_METHOD = {'AUTO' | 'EXACT' | 'APPROX' | 'HIST'},
  - ツリー構築アルゴリズムのタイプ
  - デフォルト値は AUTO
  - `リソースの使用量を減らすために、大規模なデータセットには HIST をおすすめ`とあるのでHISTが良いかも
- MIN_TREE_CHILD_WEIGHT = int64_value,
  - 子でさらにパーティショニングを行う場合に必要になるインスタンスの重みの最小合計
  - デフォルト値 1
  - 大きいほど保守的なアルゴリズム(過学習を抑制？)
  - 多分 min_child_weight
    - であれば葉を分岐するために最低限必要となる葉を構成するデータ数
- COLSAMPLE_BYTREE = float64_value,
  - 各ツリーを構築するときの列のサブサンプリング率。
  - デフォルト値 1
  - colsample_bytree
- COLSAMPLE_BYLEVEL = float64_value,
  - 各レベルの列のサブサンプリング率。
  - デフォルト 1
  - colsample_bylevel
  - subsampleとcolsample_bytreeを設定していればこのパラメータまでチューニングする必要はない  
- COLSAMPLE_BYNODE = float64_value,
  - 各ノードの列のサブサンプリングル率
  - デフォルト1
  - colsample_bynodeってのがあるっぽい
- MIN_SPLIT_LOSS = float64_value,
         MAX_TREE_DEPTH = int64_value,
         SUBSAMPLE = float64_value,
         AUTO_CLASS_WEIGHTS = { TRUE | FALSE },
         CLASS_WEIGHTS = struct_array,
         L1_REG = float64_value,
         L2_REG = float64_value,
         EARLY_STOP = { TRUE | FALSE },
         LEARN_RATE = float64_value,
         
         INPUT_LABEL_COLS = string_array,
         MAX_ITERATIONS = int64_value,
         MIN_REL_PROGRESS = float64_value,
         
- DATA_SPLIT_METHOD = { 'AUTO_SPLIT' | 'RANDOM' | 'CUSTOM' | 'SEQ' | 'NO_SPLIT' },
  - early stoppingに使用される評価データの選び方
  - NO_SPLIT: 分割しない
  - SEQ:
    - 順序付け可能なデータ型（NUMERIC、STRING、TIMESTAMP）で、分割値がしきい値を下回る行はをトレーニングデータ
    - 残りの行（NULL を含む）は、評価データとして使用
  - CUSTOM: Bool型で判断
  - RANDOM: ランダム
  - AUTO_SPLIT:
    - 入力データが 500 行未満→すべての行をトレーニングデータとして使用
    - 入力データが 500～50,000 行→データの 20% をRANDOMで評価データとして使用
    - 入力データが 50,000 行を超える→10,000 行が RANDOMで評価データとして使用
- DATA_SPLIT_EVAL_FRACTION = float64_value,
  - 'RANDOM' と 'SEQ' 分割で使用
  - 評価に使用するデータの割合
  - 小数点2まで
- DATA_SPLIT_COL = string_value
  - データの分割に使用する列
  - DATA_SPLIT_METHODが
    - CUSTOM: BOOLでTrueやNullは評価データ、Falseは学習データとされる
    - SEQ: 対応する列の最後の n 行が評価データ(nはDATA_SPLIT_EVAL_FRACTIONで指定された値)
  

## やりたいこと

### 特徴量

## Discussion & Notebook
