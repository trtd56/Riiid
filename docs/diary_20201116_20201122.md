# diary_20201116_20201122
## 実験
|モデル名|Loss|AUC|LB|memo|
|--|--|--|--|--|
|xgb_v13_07|0.5450|0.7551|0.763|baseline|
|xgb_v13_08|0.5392|0.7531||lectureの特徴追加|
|xgb_v13_09|0.5450|0.7551||partを追加|
|xgb_v13_10|0.5451|0.7551||bundle_idで一緒に出る数|
|xgb_v13_11|0.5378|0.7645|0.767|timediff|
|xgb_v13_12|0.5372|0.7652||lecture leak修正|


## 課題
### lectureモデルのLBスコアが低い
- feature更新モデルっぽい→[Notebook](https://www.kaggle.com/its7171/lgbm-with-loop-feature-engineering)

### 特徴量
- ミスってるときに選びやすい番号とか？
- shapとかで重要度計算
- bundle_idとか
  - ユーザーごとに出される問題にパターンがありそう？
  - 次に出される問題を予測してみるとか
- prior_question_*
  - 同じ問題を繰り返し出してたりする(確認のため？)

### 課金
- 無課金はpart2, 5のみらしい

### モデル
- NNとか試す
- Transformer
  - [SAINT(元論文)の解説Discussion](https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/195632)

## メモ

### Knowlege Tracking
- まとめDiscussio: https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/189962

### pd.mergeの高速化(left joinを使う)
- https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/197023
