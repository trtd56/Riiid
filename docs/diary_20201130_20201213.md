# diary_20201130_20201213

## 実験
|モデル名|Loss|AUC|LB|memo|
|--|--|--|--|--|
|__xgb_v14_06__|__0.5347__|__0.7679__|__0.771__|__baseline__|
|xgb_v15_01_f0|0.5335|0.7693||tagごとの確率にする|
|xgb_v15_02_f0|0.5319|0.7712|0.774|累積値も特徴量に入れちゃう|
|xgb_v15_03_f0|0.5321|0.7710||DART, TREE|
|xgb_v15_04_f0|0.5321|0.7710||DART, FOREST|
|xgb_v15_05_f0|0.5321|0.7709||correct numを除く|
|xgb_v15_06_f0|0.5311|0.7721||Window正解率追加 w100|
|xgb_v15_07_f0|0.5312|0.7719||Window正解率追加 w100,200|
|xgb_v15_08_f0|0.5311|0.7721||Window正解率追加 w100,300|
|xgb_v15_09_f0|0.5310|0.7722||Window正解率追加 w200 only|
|xgb_v15_10_f0|0.5316|0.7715||Window正解率追加 w100~500|
|xgb_v15_11_f0|0.5285|0.7750||300 iter|
|xgb_v15_12_f0|error|error||1000 iter|
|xgb_v15_11_f0|0.5285|0.7750||300 iter, LR=0.3|

## 改善策
- 例外的なユーザーを削除
  - ~~データが少ないユーザーを除外するとか~~
    - 一杯やってるユーザーにオーバーフィットしちゃう？
  - あまりやってないユーザーとかの除外？
- ~~ある程度過去のデータは忘却する~~
  - ~~直近N件の正解率とか~~
    - 効きそうだけどメモリの関係で沢山乗せるのは難しそう
    - 履歴使うならNNの方がよさそう
- ~~コンテンツがまんべんなく含まれるようにvalidationを工夫？~~
  - CV ensembleしてもスコア上がらなかったのであまり意味ないかも？
- レコメンドモデルなんかうまく使えないか？
  - (NN, XGB, レコメンド)→ロジスティック回帰でstackingとか？
  
### 特徴量
- ~~ミスってるときに選びやすい番号とか？~~
  - 微妙そう
- 同じ問題
  - 前に溶いたことがある問題か？
  - 同じ問題をミスってる
    - 結構人によって違いそう
    - 基本、同じ問題の場合、ミスする可能性が高い
- ユーザーごとに出される問題のパターン分析
  - 難しい問題はどれか
  - 同じ問題に答えられているか(短期記憶 or 長期記憶)
- ユーザー累積特徴
  - 単純に説いた問題数
  - prior_question_had_explanation累計,　平均
  - prior_question_elapsed_time平均
- そのtagの正解率


## 参考資料
### 元論文のモデル(SAINT)
- Discussion: https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/195632
- 前のデータをどう学習に追加していくかがちょっと難しそう

### Knowledge Tracing
- Discussion: https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/189962
- とりあえず↑のSAINTモデルで良さそう
