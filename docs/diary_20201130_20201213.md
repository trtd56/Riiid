# diary_20201130_20201213

## 実験
|モデル名|Loss|AUC|LB|memo|
|--|--|--|--|--|
|__xgb_v14_06__|__0.5347__|__0.7679__|__0.771__|__baseline__|
|xgb_v15_01_f0|0.5335|0.7693||tagごとの確率にする|
|xgb_v15_02_f0|0.5319|0.7712|0.774|累積値も特徴量に入れちゃう|
|xgb_v15_03_f0|0.5321|0.7710||DART, TREE|
|xgb_v15_04_f0|0.5321|0.7710||DART, FOREST|
|xgb_v15_05_f0|0.5321|0.7709||correct numを除く|
|xgb_v15_06_f0|0.5311|0.7721||Window正解率追加 w100|
|xgb_v15_07_f0|0.5312|0.7719||Window正解率追加 w200|
|xgb_v15_08_f0|0.5311|0.7721||Window正解率追加 w300|
|xgb_v15_09_f0||||Window正解率追加 w200 only|
|xgb_v15_10_f0||||Window正解率追加 w50|

## 改善策
- 例外的なユーザーを削除
  - データが少ないユーザーを除外するとか
- ある程度過去のデータは忘却する
  - 直近N件の正解率とか
- ~~コンテンツがまんべんなく含まれるようにvalidationを工夫？~~
  - CV ensembleしてもスコア上がらなかったのであまり意味ないかも？
- stacking

### 特徴量
- ~~ミスってるときに選びやすい番号とか？~~
  - 微妙そう
- 同じ問題
  - 前にといったことがある問題か？
  - 同じ問題をミスってる
- ユーザーごとに出される問題のパターン分析
  - 難しい問題はどれか
  - 同じ問題に答えられているか(短期記憶 or 長期記憶)
- ユーザー累積特徴
  - 単純に説いた問題数
  - prior_question_had_explanation累計,　平均
  - prior_question_elapsed_time平均


## 参考資料
### 元論文のモデル(SAINT)
- Discussion: https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/195632
- 前のデータをどう学習に追加していくかがちょっと難しそう

### Knowledge Tracing
- Discussion: https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/189962
- とりあえず↑のSAINTモデルで良さそう
