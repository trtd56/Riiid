# 終了後の反省

- treeliteっていうのでLGBMコンパイルすると早くなるそう
- 外部データとしてEdnet datasetがつかえたようだ
- 特徴量
  - 最後の正解Xまでの問題数
  - Question x Questionの行列で、正解の共起を出す(最新10, 20, 30, ...みたいに)
  - セッションでユーザーを管理。5分触らないと別のセッションになる。
  - ラグ時間を色々
    - 以前の問題のラグ時間
    - ユーザーの平均ラグ時間
    - 問題を解くのにかかった時間を予測する簡単なモデルを作ったそう
    - 同じ問題を解いたときのラグ
  - PEBG embeddingベースの特徴([元論文](https://arxiv.org/pdf/2012.05031.pdf))
  - 最初に質問される30の質問を考慮
  - 講義をみてからの経過時間
  - 回答のヤバさを図る指標(from [ML_Bearさん](https://naotaka1128.hatenadiary.jp/entry/riiid2020))
    - みんな間違えないような問題を間違えている人はちょっとおかしい(選ばないような選択肢を選んでいる場合も)
  - ユーザーごとの正解率をWord2vecでenmbedding
  - [trueskill](https://trueskill.org/)で各問題、各ユーザーの強さをスコア化
  - stacking使うべきだった
    - 特徴量としてまえのモデルの予測値使うとか・・・
  - tagのword2vec
- target encodeのスムージングが効いたそう
  - [元論文](https://dl.acm.org/doi/10.1145/507533.507538)
  - 正則化みたいな感じ
- メモリ管理
  - 軽いところはpickleで事前ロードで良さそうだったけど、h5で持って実行時ロードという方法があったようだ
  - 1%のデータでもLGBMで60位とかなれたみたい([discussion](https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/209586))
- コンテンツはtagとかみみっちい事言わないでエンジニアリングを頑張ってコンテンツを乗っければよかった
  - numpy.memmap, lil matrixとか使える？
  -  こんな方法あるみたい([元スレ](https://twitter.com/RyutaroYamauchi/status/1343919644810219520?s=20))
     - ![](https://pbs.twimg.com/media/EqaPw2cUYAINtJg?format=png&name=small)
- LSTMとかGRUとかSAKTじゃないNNモデルも考えればよかった
  - [まますさんのつぶやき](https://twitter.com/mamas16k/status/1347337653058818048?s=20)
  - [GRUの解法(6位!!!)](https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/209581)
  - Transformerは遠くをみるのが得意で近くをみるのが苦手
- 細かいラグ特徴量をこねこねするよりもTransformerに振ればよかった
  - まぁGBDTの勉強目的もあったので・・・
