# diary_20201130_20201206

## 実験
|モデル名|Loss|AUC|LB|memo|
|--|--|--|--|--|
|__xgb_v14_06__|__0.5347__|__0.7679__|__0.771__|__baseline__|
|xgb_v15_01_f0|0.5335|0.7693||tagごとの確率にする|
|xgb_v15_02_f0|0.5319|0.7712||累積値も特徴量に入れちゃう|

## 改善策
- 例外的なユーザーを削除
  - データが少ないユーザーを除外するとか
- ある程度過去のデータは忘却する
- コンテンツがまんべんなく含まれるようにvalidationを工夫？
  - CV ensembleしてもスコア上がらなかったのであまり意味ないかも？
  

### 特徴量
- ミスってるときに選びやすい番号とか？
- 同じ問題
  - 前にといったことがある問題か？
  - 同じ問題をミスってる
- ユーザーごとに出される問題のパターン分析
  - 難しい問題はどれか
  - 同じ問題に答えられているか(短期記憶 or 長期記憶)

## 参考資料
### 元論文のモデル(SAINT)
- Discussion: https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/195632
- 前のデータをどう学習に追加していくかがちょっと難しそう

### Knowledge Tracing
- Discussion: https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/189962
- とりあえず↑のSAINTモデルで良さそう
