# diary_20201026_20201101

## 課題

### 少量データでもうまく回るらしい
-  [5%のデータで特徴量作成](https://www.kaggle.com/takamichitoda/riiid-sampling-and-extract-feature?scriptVersionId=45497495)

### local foldとLBが相関しない
#### 3 foldで実験
- [cv_index抽出](https://www.kaggle.com/takamichitoda/riiid-make-cv-index?scriptVersionId=45508593)
- 確認

|Version|Loss|AUC|LB|memo|
|--|--|--|--|--|
|xgb_v7_01|0.5433|0.7530|[XX](https://www.kaggle.com/takamichitoda/riiid-xgboost-infer?scriptVersionId=45570962)|ベースライン|
|xgb_v7_02|0.5432|0.7531||part特徴量追加|
|xgb_v7_03|0.5431|0.7534|[XX](https://www.kaggle.com/takamichitoda/riiid-xgboost-infer?scriptVersionId=45576128)|partの特徴量削減しない|
|xgb_v7_04||||チューニング: Depth=5→7|

#### CVとLBの相関
- 参考Discussion: https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/192919


### アンサンブル
#### いろいろなモデルで学習
- ロジスティック回帰
- ランダムフォレスト
- NN
#### 時間削減
- mergeよりjoinのほうが早いらしい
  - 参考Discusion: https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/192779



### 特徴量
- lectureの使い方
- [特徴量スレ](https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/192137)
- [現状Bestスコアっぽい](https://www.kaggle.com/dwit392/lgbm-iii)
- [少なくていいスコア出てる](https://www.kaggle.com/johannesbruch/focus-on-important-features)
- dataflow使えるかも？

### オンライン学習
#### 広告のCTR予測の調査
#### Discussion & Notebook
- [A possible solution to partial_fit on chunks rather than on a single batch!](https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/191856)
- [RIIID: FTRL FTW !](https://www.kaggle.com/rohanrao/riiid-ftrl-ftw)

## メモ

### 例外的な学生がいるらしい
- [こちらのDiscussion](https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/193365)
- 適当に済ませて(正解率0.27)いる
- 学習データから除外するべき？

### SAINT+
- コンペオーナーの提供するTransformerベースのモデル
- AUC=0.79とか行くっぽい
- [元論文](https://arxiv.org/pdf/2010.12042.pdf)
- [Discussion](https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/193250)
