# diary_20201026_20201101

## 課題

### 少量データでもうまく回るらしい
-  [10%のデータで特徴量作成](https://www.kaggle.com/takamichitoda/riiid-sampling-and-extract-feature?scriptVersionId=45581247)
- 累計計算(cumsum)がうまくいった


### local foldとLBが相関しない
#### 3 foldで実験
- [cv_index抽出](https://www.kaggle.com/takamichitoda/riiid-make-cv-index?scriptVersionId=45508593)
- 確認

|Version|Loss|AUC|LB|memo|
|--|--|--|--|--|
|xgb_v7_01|0.5433|0.7530|~~[0.748](https://www.kaggle.com/takamichitoda/riiid-xgboost-infer?scriptVersionId=45570962)~~ [XX](https://www.kaggle.com/takamichitoda/riiid-xgboost-infer?scriptVersionId=45593758)|ベースライン(特徴量v1使ってた)|
|xgb_v7_02|0.5432|0.7531||part特徴量追加(特徴量v1使ってた)|
|xgb_v7_03|0.5431|0.7534|~~[0.740](https://www.kaggle.com/takamichitoda/riiid-xgboost-infer?scriptVersionId=45576128)~~ [XX](https://www.kaggle.com/takamichitoda/riiid-xgboost-infer?scriptVersionId=45593815)|partの特徴量削減しない(特徴量v1使ってた)|
|xgb_v7_04|0.5411|0.7557|~~[0.737](https://www.kaggle.com/takamichitoda/riiid-xgboost-infer?scriptVersionId=45578193)~~ [XX](https://www.kaggle.com/takamichitoda/riiid-xgboost-infer?scriptVersionId=45593905)|チューニング: Depth=5→7(特徴量v1使ってた)|
|xgb_v7_05|0.5407|0.7563|~~[0.729](https://www.kaggle.com/takamichitoda/riiid-xgboost-infer?scriptVersionId=45579755)~~ [0.724](https://www.kaggle.com/c/riiid-test-answer-prediction/submissions)|チューニング: Depth=7→9(~~特徴量v1使ってた~~fix)|
|xgb_v7_06|0.5425|0.7539|[0.741](https://www.kaggle.com/takamichitoda/riiid-xgboost-infer?scriptVersionId=45641296)|ベースライン|
|xgb_v7_07|0.5409|0.7558||ベースライン+チューニング: Depth=5→7|
|xgb_v7_08|0.5402|0.7567|[0.728](https://www.kaggle.com/takamichitoda/riiid-xgboost-infer?scriptVersionId=45641924)|ベースライン+チューニング: Depth=7→9|
|xgb_v8_01|0.6652|0.6565||行ごとの正解率only|
|xgb_v8_02|0.5266|0.7738|[Updateなし: XX](https://www.kaggle.com/takamichitoda/riiid-xgboost-infer-save-user-correct?scriptVersionId=45651961) / [Updateあり: XX](https://www.kaggle.com/takamichitoda/riiid-xgboost-infer-save-user-correct?scriptVersionId=45666562)|ベースライン+行ごとの正解率|


- 特徴量選択

|Version|Loss|AUC|LB|memo|
|--|--|--|--|--|
|xgb_v09_01|0.5154|0.7870||既存のuser特徴を落とした|
|xgb_v10_01|0.5811|0.6982||既存のuser特徴を落とした+既存のquestionを落とした+tagのohe追加|
|xgb_v10_02|0.5154|0.7869||既存のuser特徴を落とした+tagのohe追加|
|xgb_v10_03|0.5197|0.7828||既存のuser特徴を落とした+tagのohe追加+new question特徴|
|xgb_v10_04|0.5214|0.7811||既存のuser特徴を落とした+new question特徴|

- xgb_v10_03
  - [updateなし](https://www.kaggle.com/takamichitoda/riiid-xgboost-infer-save-user-correct?scriptVersionId=45719792)
  - [timeのみupdate](https://www.kaggle.com/takamichitoda/riiid-xgboost-infer-save-user-correct?scriptVersionId=45721888)
  - [userもupdate](https://www.kaggle.com/takamichitoda/riiid-xgboost-infer-save-user-correct?scriptVersionId=45723460)

- 以前の5 foldでの実験

|Version|Loss|AUC|LB|memo|
|--|--|--|--|--|
|xgb_v6_06|0.5375|0.7512|0.744|User+Question特徴量 & 選択(56個)|
|xgb_v6_10|0.5352|0.7533|0.731|Part特徴を追加+パラメータ調整|

#### CVとLBの相関
- 参考Discussion: https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/192919


### アンサンブル
#### いろいろなモデルで学習
- ロジスティック回帰
- ランダムフォレスト
- NN
#### 時間削減
- mergeよりjoinのほうが早いらしい
  - 参考Discusion: https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/192779

### 特徴量
- lectureの使い方
- [特徴量スレ](https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/192137)
- [現状Bestスコアっぽい](https://www.kaggle.com/dwit392/lgbm-iii)
- [少なくていいスコア出てる](https://www.kaggle.com/johannesbruch/focus-on-important-features)
- dataflow使えるかも？
- SQLの累計計算使って各行の正解率出せないか？

### オンライン学習
#### 広告のCTR予測の調査
#### Discussion & Notebook
- [A possible solution to partial_fit on chunks rather than on a single batch!](https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/191856)
- [RIIID: FTRL FTW !](https://www.kaggle.com/rohanrao/riiid-ftrl-ftw)

## メモ

### 例外的な学生がいるらしい
- [こちらのDiscussion](https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/193365)
- 適当に済ませて(正解率0.27)いる
- 学習データから除外するべき？

### SAINT+
- コンペオーナーの提供するTransformerベースのモデル
- AUC=0.79とか行くっぽい
- [元論文](https://arxiv.org/pdf/2010.12042.pdf)
- [Discussion](https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/193250)
